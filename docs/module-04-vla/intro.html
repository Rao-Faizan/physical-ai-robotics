<!doctype html>
<html lang="en-US" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-module-04-vla/intro" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Module 4: Vision-Language-Action Integration | Physical AI &amp; Humanoid Robotics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://rao-faizan.github.io/physical-ai-robotics/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://rao-faizan.github.io/physical-ai-robotics/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://rao-faizan.github.io/physical-ai-robotics/docs/module-04-vla/intro"><meta data-rh="true" property="og:locale" content="en_US"><meta data-rh="true" property="og:locale:alternate" content="ur_PK"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Module 4: Vision-Language-Action Integration | Physical AI &amp; Humanoid Robotics"><meta data-rh="true" name="description" content="Overview"><meta data-rh="true" property="og:description" content="Overview"><link data-rh="true" rel="icon" href="/physical-ai-robotics/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://rao-faizan.github.io/physical-ai-robotics/docs/module-04-vla/intro"><link data-rh="true" rel="alternate" href="https://rao-faizan.github.io/physical-ai-robotics/docs/module-04-vla/intro" hreflang="en-US"><link data-rh="true" rel="alternate" href="https://rao-faizan.github.io/physical-ai-robotics/ur/docs/module-04-vla/intro" hreflang="ur-PK"><link data-rh="true" rel="alternate" href="https://rao-faizan.github.io/physical-ai-robotics/docs/module-04-vla/intro" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Module 4: Vision-Language-Action Integration","item":"https://rao-faizan.github.io/physical-ai-robotics/docs/module-04-vla/intro"}]}</script><link rel="stylesheet" href="/physical-ai-robotics/assets/css/styles.d16c4487.css">
<script src="/physical-ai-robotics/assets/js/runtime~main.392d4ad6.js" defer="defer"></script>
<script src="/physical-ai-robotics/assets/js/main.e46cc962.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/physical-ai-robotics/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/physical-ai-robotics/"><div class="navbar__logo"><img src="/physical-ai-robotics/img/logo.svg" alt="Physical AI Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/physical-ai-robotics/img/logo.svg" alt="Physical AI Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Physical AI &amp; Robotics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/physical-ai-robotics/docs/intro">Course</a><a class="navbar__item navbar__link" href="/physical-ai-robotics/personalize">Personalize</a><a class="navbar__item navbar__link" href="/physical-ai-robotics/personalize-content">Personalize Content</a><a class="navbar__item navbar__link" href="/physical-ai-robotics/translate">Urdu Translation</a><a class="navbar__item navbar__link" href="/physical-ai-robotics/chatbot">AI Tutor</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/physical-ai-robotics/signup">Sign Up</a><a class="navbar__item navbar__link" href="/physical-ai-robotics/signin">Sign In</a><a href="https://github.com/Rao-Faizan/physical-ai-robotics" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="navbarControls_AC5M"><button class="personalizeBtn_VyDp" title="Personalize content based on your experience level">‚ö° Personalize</button><button class="translateBtn_xyag" title="Translate to Urdu">üåê ÿßÿ±ÿØŸà</button></div><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/physical-ai-robotics/docs/intro"><span title="Physical AI &amp; Humanoid Robotics" class="linkLabel_WmDU">Physical AI &amp; Humanoid Robotics</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/physical-ai-robotics/docs/module-01-ros2/intro"><span title="Module 1: ROS 2 Fundamentals" class="categoryLinkLabel_W154">Module 1: ROS 2 Fundamentals</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics/docs/module-01-ros2/intro"><span title="Module 1: ROS 2 Fundamentals" class="linkLabel_WmDU">Module 1: ROS 2 Fundamentals</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics/docs/module-01-ros2/week-3-basics"><span title="Week 3: ROS 2 Basics" class="linkLabel_WmDU">Week 3: ROS 2 Basics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics/docs/module-01-ros2/week-3-nodes-topics"><span title="Week 3: Nodes and Topics" class="linkLabel_WmDU">Week 3: Nodes and Topics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics/docs/module-01-ros2/week-4-services-actions"><span title="Week 4: Services and Actions" class="linkLabel_WmDU">Week 4: Services and Actions</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics/docs/module-01-ros2/week-5-urdf"><span title="Week 5: URDF for Humanoid Robots" class="linkLabel_WmDU">Week 5: URDF for Humanoid Robots</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics/docs/module-01-ros2/week-5-control"><span title="Week 5: ros2_control Framework" class="linkLabel_WmDU">Week 5: ros2_control Framework</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics/docs/module-01-ros2/week-5-complete-urdf"><span title="Week 5: Complete Humanoid URDF Example" class="linkLabel_WmDU">Week 5: Complete Humanoid URDF Example</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/physical-ai-robotics/docs/module-02-simulation/intro"><span title="Module 2: Gazebo &amp; Unity Simulation" class="categoryLinkLabel_W154">Module 2: Gazebo &amp; Unity Simulation</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics/docs/module-02-simulation/intro"><span title="Module 2: Gazebo &amp; Unity Simulation" class="linkLabel_WmDU">Module 2: Gazebo &amp; Unity Simulation</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics/docs/module-02-simulation/week-6-gazebo-basics"><span title="Week 6: Gazebo Basics" class="linkLabel_WmDU">Week 6: Gazebo Basics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics/docs/module-02-simulation/week-6-physics"><span title="Week 6: Physics Configuration for Humanoid Robots" class="linkLabel_WmDU">Week 6: Physics Configuration for Humanoid Robots</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics/docs/module-02-simulation/week-7-sensors"><span title="Week 7: Sensor Simulation" class="linkLabel_WmDU">Week 7: Sensor Simulation</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics/docs/module-02-simulation/week-7-unity"><span title="Week 7: Unity for Robotics" class="linkLabel_WmDU">Week 7: Unity for Robotics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics/docs/module-02-simulation/week-7-worlds"><span title="Week 7: Building Custom Simulation Worlds" class="linkLabel_WmDU">Week 7: Building Custom Simulation Worlds</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/physical-ai-robotics/docs/module-03-isaac/intro"><span title="Module 3: NVIDIA Isaac Platform" class="categoryLinkLabel_W154">Module 3: NVIDIA Isaac Platform</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics/docs/module-03-isaac/intro"><span title="Module 3: NVIDIA Isaac Platform for Physical AI" class="linkLabel_WmDU">Module 3: NVIDIA Isaac Platform for Physical AI</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics/docs/module-03-isaac/week-8-isaac-sim"><span title="Week 8: Isaac Sim Fundamentals" class="linkLabel_WmDU">Week 8: Isaac Sim Fundamentals</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics/docs/module-03-isaac/week-8-synthetic-data"><span title="Week 8: Synthetic Data Generation" class="linkLabel_WmDU">Week 8: Synthetic Data Generation</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics/docs/module-03-isaac/week-9-isaac-ros"><span title="Week 9: Isaac ROS Deployment" class="linkLabel_WmDU">Week 9: Isaac ROS Deployment</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics/docs/module-03-isaac/week-9-perception"><span title="Week 9: Perception for Manipulation" class="linkLabel_WmDU">Week 9: Perception for Manipulation</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics/docs/module-03-isaac/week-10-nav2"><span title="Week 10: Navigation with Nav2" class="linkLabel_WmDU">Week 10: Navigation with Nav2</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics/docs/module-03-isaac/week-10-bipedal-locomotion"><span title="Week 10: Bipedal Locomotion Control" class="linkLabel_WmDU">Week 10: Bipedal Locomotion Control</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/physical-ai-robotics/docs/module-04-vla/intro"><span title="Module 4: Vision-Language-Action (VLA)" class="categoryLinkLabel_W154">Module 4: Vision-Language-Action (VLA)</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/physical-ai-robotics/docs/module-04-vla/intro"><span title="Module 4: Vision-Language-Action Integration" class="linkLabel_WmDU">Module 4: Vision-Language-Action Integration</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics/docs/module-04-vla/week-11-voice-to-action"><span title="Week 11: Voice-to-Action Pipeline" class="linkLabel_WmDU">Week 11: Voice-to-Action Pipeline</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics/docs/module-04-vla/week-11-llm-planning"><span title="Week 11: LLM-Based Task Planning" class="linkLabel_WmDU">Week 11: LLM-Based Task Planning</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics/docs/module-04-vla/week-12-multimodal"><span title="Week 12: Multimodal Vision-Language Fusion" class="linkLabel_WmDU">Week 12: Multimodal Vision-Language Fusion</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics/docs/module-04-vla/week-12-gesture-recognition"><span title="Week 12: Gesture Recognition for Human-Robot Interaction" class="linkLabel_WmDU">Week 12: Gesture Recognition for Human-Robot Interaction</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics/docs/module-04-vla/week-13-capstone-intro"><span title="Week 13: Capstone Project - Autonomous Humanoid with Conversational AI" class="linkLabel_WmDU">Week 13: Capstone Project - Autonomous Humanoid with Conversational AI</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics/docs/module-04-vla/week-13-capstone-implementation"><span title="Week 13: Capstone Implementation - Complete System Integration" class="linkLabel_WmDU">Week 13: Capstone Implementation - Complete System Integration</span></a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/physical-ai-robotics/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Module 4: Vision-Language-Action (VLA)</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Module 4: Vision-Language-Action Integration</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="controls_SOIZ"><div class="buttonGroup_vVSy"><button class="personalizeBtn_rtZA" title="Adjust content based on your experience level">‚ö° Personalize for Me</button><button class="translateBtn_lpzv" title="Translate to Urdu while preserving technical terms">üåê Urdu Translation</button></div></div><div class="theme-doc-markdown markdown"><header><h1>Module 4: Vision-Language-Action Integration</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="overview">Overview<a href="#overview" class="hash-link" aria-label="Direct link to Overview" title="Direct link to Overview" translate="no">‚Äã</a></h2>
<p>Welcome to Module 4, where we explore the convergence of Large Language Models (LLMs) with robotics to create embodied AI agents capable of understanding human intent, perceiving their environment, and executing physical actions. This module represents the frontier of humanoid robotics‚Äîsystems that don&#x27;t just follow pre-programmed routines, but interpret natural language commands, reason about visual scenes, and adaptively plan motion sequences.</p>
<p>Vision-Language-Action (VLA) models unify three critical modalities: visual perception (cameras, depth sensors), natural language understanding (speech, text), and motor control (joint actuation, grasping). Unlike traditional robotics pipelines where perception, planning, and control operate independently, VLA architectures learn joint representations that map directly from multimodal inputs to robot actions. This end-to-end approach enables behaviors like &quot;Pick up the red mug on the left shelf&quot;‚Äîrequiring visual grounding (identifying &quot;red mug&quot;), spatial reasoning (&quot;left shelf&quot;), and manipulation planning (grasp trajectory).</p>
<p><img decoding="async" loading="lazy" alt="Vision-Language-Action Integration" src="/physical-ai-robotics/assets/images/ai-5-39424af8dc30e12934739e7a0b39b9d0.png" width="736" height="1349" class="img_ev3q"></p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="what-is-vla">What is VLA?<a href="#what-is-vla" class="hash-link" aria-label="Direct link to What is VLA?" title="Direct link to What is VLA?" translate="no">‚Äã</a></h2>
<p><img decoding="async" loading="lazy" alt="VLA Architecture" src="data:image/svg+xml;base64,<svg width="900" height="600" xmlns="http://www.w3.org/2000/svg">
  <!-- White Background -->
  <rect width="900" height="600" fill="#FFFFFF" stroke="#00D4FF" stroke-width="3"/>

  <!-- Title -->
  <text x="450" y="35" font-family="Arial, sans-serif" font-size="24" fill="#1A1A1A" text-anchor="middle" font-weight="bold">Vision-Language-Action (VLA) Architecture</text>

  <!-- Input Modalities Section -->
  <text x="450" y="70" font-family="Arial, sans-serif" font-size="16" fill="#8A2BE2" text-anchor="middle" font-weight="bold">Multimodal Input Layer</text>

  <!-- Voice Input -->
  <rect x="50" y="90" width="170" height="90" fill="#E0F7FF" stroke="#00D4FF" stroke-width="3" rx="8"/>
  <text x="135" y="115" font-family="Arial, sans-serif" font-size="15" fill="#00D4FF" text-anchor="middle" font-weight="bold">🎤 Voice</text>
  <text x="135" y="138" font-family="Arial, sans-serif" font-size="12" fill="#1A1A1A" text-anchor="middle">Whisper API</text>
  <text x="135" y="158" font-family="Arial, sans-serif" font-size="11" fill="#555" text-anchor="middle">Speech → Text</text>
  <text x="135" y="173" font-family="Arial, sans-serif" font-size="10" fill="#8A2BE2" text-anchor="middle">"Pick up the cup"</text>

  <!-- Visual Input -->
  <rect x="240" y="90" width="170" height="90" fill="#E0F7FF" stroke="#00D4FF" stroke-width="3" rx="8"/>
  <text x="325" y="115" font-family="Arial, sans-serif" font-size="15" fill="#00D4FF" text-anchor="middle" font-weight="bold">👁 Vision</text>
  <text x="325" y="138" font-family="Arial, sans-serif" font-size="12" fill="#1A1A1A" text-anchor="middle">CLIP / GPT-4V</text>
  <text x="325" y="158" font-family="Arial, sans-serif" font-size="11" fill="#555" text-anchor="middle">RGB-D + Semantic</text>
  <text x="325" y="173" font-family="Arial, sans-serif" font-size="10" fill="#8A2BE2" text-anchor="middle">Object detection</text>

  <!-- Gesture Input -->
  <rect x="430" y="90" width="170" height="90" fill="#E0F7FF" stroke="#00D4FF" stroke-width="3" rx="8"/>
  <text x="515" y="115" font-family="Arial, sans-serif" font-size="15" fill="#00D4FF" text-anchor="middle" font-weight="bold">✋ Gesture</text>
  <text x="515" y="138" font-family="Arial, sans-serif" font-size="12" fill="#1A1A1A" text-anchor="middle">MediaPipe</text>
  <text x="515" y="158" font-family="Arial, sans-serif" font-size="11" fill="#555" text-anchor="middle">Hand tracking</text>
  <text x="515" y="173" font-family="Arial, sans-serif" font-size="10" fill="#8A2BE2" text-anchor="middle">21 landmarks</text>

  <!-- Text Input -->
  <rect x="620" y="90" width="170" height="90" fill="#E0F7FF" stroke="#00D4FF" stroke-width="3" rx="8"/>
  <text x="705" y="115" font-family="Arial, sans-serif" font-size="15" fill="#00D4FF" text-anchor="middle" font-weight="bold">📝 Text</text>
  <text x="705" y="138" font-family="Arial, sans-serif" font-size="12" fill="#1A1A1A" text-anchor="middle">Natural Language</text>
  <text x="705" y="158" font-family="Arial, sans-serif" font-size="11" fill="#555" text-anchor="middle">Task commands</text>
  <text x="705" y="173" font-family="Arial, sans-serif" font-size="10" fill="#8A2BE2" text-anchor="middle">Written instructions</text>

  <!-- Arrows to LLM -->
  <defs>
    <marker id="arrow" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto">
      <polygon points="0 0, 10 3, 0 6" fill="#8A2BE2"/>
    </marker>
  </defs>
  <line x1="135" y1="180" x2="200" y2="220" stroke="#8A2BE2" stroke-width="2" marker-end="url(#arrow)"/>
  <line x1="325" y1="180" x2="325" y2="220" stroke="#8A2BE2" stroke-width="2" marker-end="url(#arrow)"/>
  <line x1="515" y1="180" x2="450" y2="220" stroke="#8A2BE2" stroke-width="2" marker-end="url(#arrow)"/>
  <line x1="705" y1="180" x2="600" y2="220" stroke="#8A2BE2" stroke-width="2" marker-end="url(#arrow)"/>

  <!-- LLM Planning Layer -->
  <rect x="100" y="220" width="700" height="120" fill="#F0E6FF" stroke="#8A2BE2" stroke-width="4" rx="10"/>
  <text x="450" y="250" font-family="Arial, sans-serif" font-size="18" fill="#8A2BE2" text-anchor="middle" font-weight="bold">🧠 Large Language Model (GPT-4 / Claude)</text>
  <text x="450" y="275" font-family="Arial, sans-serif" font-size="14" fill="#1A1A1A" text-anchor="middle">Task Planning & Chain-of-Thought Reasoning</text>
  <text x="450" y="298" font-family="Arial, sans-serif" font-size="12" fill="#555" text-anchor="middle">1. Thought: "User wants me to grasp the red cup on the left shelf"</text>
  <text x="450" y="316" font-family="Arial, sans-serif" font-size="12" fill="#555" text-anchor="middle">2. Action: call vision_grounding(object="red cup", location="left shelf")</text>
  <text x="450" y="332" font-family="Arial, sans-serif" font-size="12" fill="#555" text-anchor="middle">3. Observation: Cup detected at pose (x=0.5, y=-0.3, z=1.2)</text>

  <!-- Arrow to Action Layer -->
  <line x1="450" y1="340" x2="450" y2="375" stroke="#8A2BE2" stroke-width="3" marker-end="url(#arrow)"/>
  <text x="490" y="365" font-family="Arial, sans-serif" font-size="12" fill="#8A2BE2" text-anchor="start">Decompose into primitives</text>

  <!-- Action Primitives Layer -->
  <text x="450" y="400" font-family="Arial, sans-serif" font-size="16" fill="#00D4FF" text-anchor="middle" font-weight="bold">Robot Action Primitives</text>

  <rect x="50" y="415" width="180" height="80" fill="#E0F7FF" stroke="#00D4FF" stroke-width="3" rx="8"/>
  <text x="140" y="440" font-family="Arial, sans-serif" font-size="14" fill="#00D4FF" text-anchor="middle" font-weight="bold">Navigate</text>
  <text x="140" y="462" font-family="Arial, sans-serif" font-size="11" fill="#1A1A1A" text-anchor="middle">navigate_to(goal)</text>
  <text x="140" y="480" font-family="Arial, sans-serif" font-size="10" fill="#555" text-anchor="middle">Nav2 + costmap</text>

  <rect x="250" y="415" width="180" height="80" fill="#E0F7FF" stroke="#00D4FF" stroke-width="3" rx="8"/>
  <text x="340" y="440" font-family="Arial, sans-serif" font-size="14" fill="#00D4FF" text-anchor="middle" font-weight="bold">Reach</text>
  <text x="340" y="462" font-family="Arial, sans-serif" font-size="11" fill="#1A1A1A" text-anchor="middle">move_to(x, y, z)</text>
  <text x="340" y="480" font-family="Arial, sans-serif" font-size="10" fill="#555" text-anchor="middle">Path planning</text>

  <rect x="450" y="415" width="180" height="80" fill="#E0F7FF" stroke="#00D4FF" stroke-width="3" rx="8"/>
  <text x="540" y="440" font-family="Arial, sans-serif" font-size="14" fill="#00D4FF" text-anchor="middle" font-weight="bold">Grasp</text>
  <text x="540" y="462" font-family="Arial, sans-serif" font-size="11" fill="#1A1A1A" text-anchor="middle">grasp(pose, force)</text>
  <text x="540" y="480" font-family="Arial, sans-serif" font-size="10" fill="#555" text-anchor="middle">Inverse kinematics</text>

  <rect x="650" y="415" width="180" height="80" fill="#E0F7FF" stroke="#00D4FF" stroke-width="3" rx="8"/>
  <text x="740" y="440" font-family="Arial, sans-serif" font-size="14" fill="#00D4FF" text-anchor="middle" font-weight="bold">Place</text>
  <text x="740" y="462" font-family="Arial, sans-serif" font-size="11" fill="#1A1A1A" text-anchor="middle">place_at(target)</text>
  <text x="740" y="480" font-family="Arial, sans-serif" font-size="10" fill="#555" text-anchor="middle">Collision check</text>

  <!-- Arrow to ROS Layer -->
  <line x1="450" y1="495" x2="450" y2="525" stroke="#00D4FF" stroke-width="3" marker-end="url(#arrow)"/>

  <!-- ROS 2 Execution Layer -->
  <rect x="100" y="525" width="700" height="50" fill="#E0F7FF" stroke="#00D4FF" stroke-width="3" rx="8"/>
  <text x="450" y="555" font-family="Arial, sans-serif" font-size="16" fill="#00D4FF" text-anchor="middle" font-weight="bold">ROS 2 Control Layer (ros2_control + MoveIt 2)</text>

  <!-- Legend -->
  <rect x="50" y="15" width="15" height="15" fill="#E0F7FF" stroke="#00D4FF" stroke-width="2"/>
  <text x="75" y="27" font-family="Arial, sans-serif" font-size="11" fill="#1A1A1A" text-anchor="start">Perception/Planning</text>

  <rect x="200" y="15" width="15" height="15" fill="#F0E6FF" stroke="#8A2BE2" stroke-width="2"/>
  <text x="225" y="27" font-family="Arial, sans-serif" font-size="11" fill="#1A1A1A" text-anchor="start">LLM Reasoning</text>
</svg>
" width="900" height="600" class="img_ev3q">
<em>Figure 4.1: Vision-Language-Action architecture showing multimodal inputs (voice, visual, gesture, text) flowing through GPT-4 for task planning and execution via ROS 2</em></p>
<p><strong>Vision-Language-Action (VLA)</strong> refers to neural architectures that process visual observations and language instructions to produce robot control commands. The core innovation is a shared embedding space where:</p>
<ul>
<li class=""><strong>Vision embeddings</strong> capture 3D scene geometry, object semantics, and spatial relationships</li>
<li class=""><strong>Language embeddings</strong> encode task goals, constraints, and temporal sequences (&quot;first open the drawer, then grasp&quot;)</li>
<li class=""><strong>Action embeddings</strong> represent feasible robot trajectories in joint or task space</li>
</ul>
<p>Modern VLA models like RT-2 (Robotics Transformer 2) and PaLM-E leverage pre-trained vision-language models (CLIP, GPT-4V) and fine-tune them on robot demonstration data. This transfer learning approach allows robots to benefit from internet-scale knowledge‚Äîa robot that has never seen a &quot;whisk&quot; in training can still identify one by leveraging language model understanding of kitchen utensils.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="embodied-ai-agents">Embodied AI Agents<a href="#embodied-ai-agents" class="hash-link" aria-label="Direct link to Embodied AI Agents" title="Direct link to Embodied AI Agents" translate="no">‚Äã</a></h2>
<p><strong>Embodied AI</strong> emphasizes that intelligence arises from interaction with the physical world, not just symbolic reasoning. An embodied agent must:</p>
<ol>
<li class=""><strong>Ground language in perception</strong>: &quot;The blue box&quot; requires visual identification of objects matching color and shape descriptors</li>
<li class=""><strong>Maintain world models</strong>: Track object states over time (door is now open, mug has been grasped)</li>
<li class=""><strong>Execute closed-loop control</strong>: Adapt actions based on sensory feedback (adjust grasp force if object slips)</li>
<li class=""><strong>Handle uncertainty</strong>: Recover from partial observations, sensor noise, and dynamic environments</li>
</ol>
<p>Traditional AI systems operate on abstract symbols; embodied AI agents operate on pixels, point clouds, and torque commands. This grounding forces models to learn physics-aware representations‚Äîunderstanding that pushing a heavy object requires more force than a light one, or that grasping a mug by the handle is more stable than the rim.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="multimodal-learning">Multimodal Learning<a href="#multimodal-learning" class="hash-link" aria-label="Direct link to Multimodal Learning" title="Direct link to Multimodal Learning" translate="no">‚Äã</a></h2>
<p>VLA systems employ <strong>multimodal learning</strong> to fuse heterogeneous data streams into coherent action policies. Key techniques include:</p>
<p><strong>Cross-Modal Attention</strong>: Transformer architectures that attend jointly over vision and language tokens. When processing &quot;pick up the left apple,&quot; attention weights should focus on visual tokens corresponding to leftmost apple instances, not right-side fruits.</p>
<p><strong>Contrastive Learning</strong>: Methods like CLIP learn vision-language alignment by contrasting positive pairs (image + correct caption) against negative pairs (image + mismatched captions). This creates a shared embedding space where semantically similar concepts cluster together.</p>
<p><strong>Action Tokenization</strong>: Representing robot actions as discrete tokens enables language models to &quot;speak robot&quot;‚Äîgenerating action sequences autoregressively like text generation. RT-2 discretizes continuous joint positions into 256 bins, treating each configuration as a vocabulary token.</p>
<p><strong>Hierarchical Policies</strong>: LLMs generate high-level task plans (&quot;navigate to kitchen, open fridge, grasp milk&quot;) while low-level controllers handle motion primitives. This separation of concerns improves sample efficiency‚Äîthe LLM doesn&#x27;t need to learn low-level PID control.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="module-structure">Module Structure<a href="#module-structure" class="hash-link" aria-label="Direct link to Module Structure" title="Direct link to Module Structure" translate="no">‚Äã</a></h2>
<p>This module progresses over 3 weeks:</p>
<p><strong>Week 11: Voice and Language Integration</strong></p>
<ul>
<li class="">OpenAI Whisper for speech-to-text transcription</li>
<li class="">Intent classification from natural language commands</li>
<li class="">GPT-4 for task planning and chain-of-thought reasoning</li>
<li class="">Prompt engineering for robot control</li>
</ul>
<p><strong>Week 12: Multimodal Perception</strong></p>
<ul>
<li class="">CLIP for zero-shot visual grounding</li>
<li class="">Referring expression comprehension (&quot;the object to the left of the red box&quot;)</li>
<li class="">MediaPipe for gesture recognition and human-robot interaction</li>
<li class="">Visual question answering for scene understanding</li>
</ul>
<p><strong>Week 13: Capstone Integration</strong></p>
<ul>
<li class="">End-to-end system: voice command ‚Üí LLM planning ‚Üí navigation ‚Üí manipulation ‚Üí feedback</li>
<li class="">Autonomous humanoid with conversational AI</li>
<li class="">Real-time multimodal fusion</li>
<li class="">Deployment on physical humanoid platform</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="prerequisites">Prerequisites<a href="#prerequisites" class="hash-link" aria-label="Direct link to Prerequisites" title="Direct link to Prerequisites" translate="no">‚Äã</a></h2>
<p>To succeed in this module, you should have:</p>
<ul>
<li class=""><strong>Deep Learning Foundations</strong>: Understanding of neural networks, transformers, attention mechanisms</li>
<li class=""><strong>Python Proficiency</strong>: Experience with PyTorch/TensorFlow, NumPy, API integration</li>
<li class=""><strong>ROS 2 Knowledge</strong>: Completion of Modules 1-3 (navigation, manipulation fundamentals)</li>
<li class=""><strong>Vision Basics</strong>: Familiarity with image processing, object detection, camera calibration</li>
<li class=""><strong>API Access</strong>: OpenAI API key for GPT-4 and Whisper (see setup instructions)</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="why-vla-for-humanoid-robotics">Why VLA for Humanoid Robotics?<a href="#why-vla-for-humanoid-robotics" class="hash-link" aria-label="Direct link to Why VLA for Humanoid Robotics?" title="Direct link to Why VLA for Humanoid Robotics?" translate="no">‚Äã</a></h2>
<p>Humanoid robots must operate in human-centric environments designed for natural language interaction. Consider daily tasks:</p>
<ul>
<li class=""><strong>&quot;Bring me my laptop from the office desk&quot;</strong>: Requires parsing location references, visual search across rooms, navigation planning, and safe handover</li>
<li class=""><strong>&quot;Help me prepare dinner&quot;</strong>: Open-ended collaboration needing contextual understanding (dinner implies kitchen, food preparation tools)</li>
<li class=""><strong>&quot;The package is too heavy, can you assist?&quot;</strong>: Opportunistic task initiation from human request, force sensing for collaborative lifting</li>
</ul>
<p>Pre-programmed finite state machines cannot handle this variability. VLA models learn generalizable policies that compose perception, language, and action‚Äîthe foundation for truly autonomous humanoid assistants.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="ethical-considerations">Ethical Considerations<a href="#ethical-considerations" class="hash-link" aria-label="Direct link to Ethical Considerations" title="Direct link to Ethical Considerations" translate="no">‚Äã</a></h2>
<p>As you develop VLA systems, maintain awareness of:</p>
<ul>
<li class=""><strong>Privacy</strong>: Speech and camera data contain sensitive information; implement secure data handling</li>
<li class=""><strong>Safety</strong>: LLM hallucinations can generate unsafe robot actions; always validate planned trajectories</li>
<li class=""><strong>Bias</strong>: Language models inherit dataset biases; test across diverse demographics and languages</li>
<li class=""><strong>Transparency</strong>: Maintain human oversight for critical tasks; implement emergency stop mechanisms</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="getting-started">Getting Started<a href="#getting-started" class="hash-link" aria-label="Direct link to Getting Started" title="Direct link to Getting Started" translate="no">‚Äã</a></h2>
<p>Ensure you have:</p>
<ul>
<li class="">Ubuntu 22.04 with ROS 2 Humble (from Module 1)</li>
<li class="">Python 3.10+ with PyTorch 2.0+</li>
<li class="">OpenAI API key (set as <code>OPENAI_API_KEY</code> environment variable)</li>
<li class="">GPU with 8GB+ VRAM (NVIDIA RTX 3060 or better recommended)</li>
<li class="">Webcam and microphone for testing</li>
</ul>
<p>Ready to build conversational robots? Proceed to <strong>Week 11: Voice-to-Action</strong> to implement speech recognition and command parsing.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/Rao-Faizan/physical-ai-robotics/tree/main/frontend/docs/module-04-vla/intro.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/physical-ai-robotics/docs/module-03-isaac/week-10-bipedal-locomotion"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Week 10: Bipedal Locomotion Control</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/physical-ai-robotics/docs/module-04-vla/week-11-voice-to-action"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Week 11: Voice-to-Action Pipeline</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#overview" class="table-of-contents__link toc-highlight">Overview</a></li><li><a href="#what-is-vla" class="table-of-contents__link toc-highlight">What is VLA?</a></li><li><a href="#embodied-ai-agents" class="table-of-contents__link toc-highlight">Embodied AI Agents</a></li><li><a href="#multimodal-learning" class="table-of-contents__link toc-highlight">Multimodal Learning</a></li><li><a href="#module-structure" class="table-of-contents__link toc-highlight">Module Structure</a></li><li><a href="#prerequisites" class="table-of-contents__link toc-highlight">Prerequisites</a></li><li><a href="#why-vla-for-humanoid-robotics" class="table-of-contents__link toc-highlight">Why VLA for Humanoid Robotics?</a></li><li><a href="#ethical-considerations" class="table-of-contents__link toc-highlight">Ethical Considerations</a></li><li><a href="#getting-started" class="table-of-contents__link toc-highlight">Getting Started</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Learning</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/physical-ai-robotics/docs/intro">Get Started</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/Rao-Faizan/physical-ai-robotics/discussions" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub Discussions<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://github.com/Rao-Faizan/physical-ai-robotics/issues" target="_blank" rel="noopener noreferrer" class="footer__link-item">Issues<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/Rao-Faizan/physical-ai-robotics" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright ¬© 2026 Physical AI & Humanoid Robotics. Built with Docusaurus.</div></div></div></footer><div class="chatWidget_CAfF"><button class="chatButton_Gsa8" aria-label="Toggle chat">üí¨</button></div></div>
</body>
</html>