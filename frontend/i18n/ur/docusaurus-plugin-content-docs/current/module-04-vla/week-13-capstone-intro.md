# ہفتہ 13: کیپسٹون پروجیکٹ - گفتگو کے AI کے ساتھ خودکار ہیومنوائڈ

![Capstone Project Introduction](/img/ai-15.png)

## پروجیکٹ کا جائزہ

کیپسٹون پروجیکٹ Module 4 کے تمام مہارتوں کو ایک مکمل انضمام شدہ خودکار ہیومنوائڈ سسٹم میں جمع کرتا ہے۔ آپ ایک گفتگو کا AI ایجنٹ تیار کریں گے جو قدرتی زبان کے کمانڈز قبول کرتا ہے، متعدد اسٹیپ ٹاسکس کا منصوبہ بندی کرتا ہے، ویژن اور زبانی جڑاؤ کے ذریعے اپنے ماحول کا ادراک کرتا ہے، اور جسمانی ایکشنز انجام دیتا ہے—تمام کے دوران صارف کو قدرتی زبان کی فیڈ بیک فراہم کرتا ہے۔

یہ پروجیکٹ ایمبیڈڈ AI میں جدید ترین کی نمائندگی کرتا ہے: سسٹمز جو انسان کے مراکز ماحول میں ادراک، ریزننگ، اور ایکشن کو بے داغ ملا دیتے ہیں۔ مکمل ہونے پر، آپ کے پاس وہی ٹیکنالوجیز کا ہاتھ سے تجربہ ہو گا جو تجارتی ہیومنوائڈ اسسٹنٹس کو طاقت دیتی ہیں جیسے کہ فیگر 02، ٹیسلا آپٹیمس، اور 1X NEO۔

## سسٹم آرکیٹیکچر

کیپسٹون پانچ بنیادی ذیلی سسٹمز کو ضم کرتا ہے:

### 1. وائس انٹرفیس لیئر
- **Whisper ASR**: ویک ورڈ ڈیٹیکشن کے ساتھ جاری اسپیچ ریکوگنیشن
- **کمانڈ پارسر**: ٹرانسکرپشنز سے انٹینٹ، اینٹیٹیز، اور پیرامیٹرز نکالیں
- **ٹیکسٹ ٹو اسپیچ**: قدرتی زبان کی فیڈ بیک تیار کریں (`pyttsx3` یا OpenAI TTS استعمال کر کے)

### 2. منصوبہ بندی اور ریزننگ انجن
- **GPT-4 ٹاسک پلینر**: ایکشن سیکوئنس میں اعلیٰ سطح کے اہداف کو ڈیکوم پوز کریں
- **ReAct کنٹرولر**: حقیقی وقت کے دوبارہ منصوبہ بندی کے ساتھ موافق منصوبہ انجام دہی
- **میموری سسٹم**: دنیا کی حالت، اشیاء کے مقامات، اور ٹاسک کی تاریخ ٹریک کریں

### 3. ملٹی موڈل ادراک
- **CLIP ویژوئل جڑاؤ**: زبانی تفصیلات کو منظر کی اشیاء میں میپ کریں
- **اشیاء کی پہچان**: YOLOv8 یا Detic انسٹینس سیگمینٹیشن کے لئے
- **ڈیپتھ ایسٹیمیشن**: 3D مقام کے لئے RGB-D کیمرہ انضمام
- **گیسچر ریکوگنیشن**: غیر زبانی کمانڈز کے لئے MediaPipe ہینڈ ٹریکنگ

### 4. نیوی گیشن اور مینوپولیشن
- **Nav2 انضمام**: ہدف کے مقامات تک خودکار نیوی گیشن
- **MoveIt 2**: بازو مینوپولیشن ٹاسکس کے لئے موشن منصوبہ بندی
- **گریس پلاننگ**: ویژوئل مشاہدات سے مستحکم گریسز کا حساب لگائیں

### 5. فیڈ بیک اور مانیٹرنگ
- **این ایکشن کی حیثیت**: تقریر کے ذریعے ٹاسک کی ترقی کی رپورٹ کریں ("کچن کی طرف جا رہا ہے...")
- **خرابی کا انتظام**: ناکامیاں ڈیٹیکٹ کریں اور انسانی مدد کی درخواست کریں
- **سیفٹی مانیٹرنگ**: کالیژن ایوائڈنس، فورس حدیں، ہنگامی بندش

## سسٹم ڈیٹا فلو

```
صارف کی آواز کا کمانڈ
    ↓
[Whisper ASR] → ٹرانسکرپشن
    ↓
[GPT-4 پارسر] → سٹرکچرڈ انٹینٹ
    ↓
[ٹاسک پلینر] → ایکشن سیکوئنس
    ↓
┌─────────────┴─────────────┐
│ ReAct انجام دہی لوپ:     │
│                           │
│ [کیمرہ فیڈ]             │
│      ↓                    │
│ [CLIP + اشیاء کی پہچان] │
│      ↓                    │
│ [ویژوئل جڑاؤ]        │
│      ↓                    │
│ [نیوی گیشن/مینوپولیشن] │
│      ↓                    │
│ [این ایکشن فیڈ بیک]      │
│      ↓                    │
│ [ٹیکسٹ ٹو اسپیچ کی حیثیت]   │
│      ↓                    │
│ اگلا قدم یا مکمل     │
└───────────────────────────┘
```

## مثالی انٹرایکشن کا منظر

**صارف**: "اے روبوٹ، کچن کی ٹیبل سے میرے لئے لال مگ لاؤ۔"

**سسٹم پروسیسنگ**:
1. **وائس**: Whisper کمانڈ کو ٹرانسکرائیب کرتا ہے
2. **پارسنگ**: GPT-4 انٹینٹ=`fetch`، شے=`red mug`، مقام=`kitchen counter` نکالتا ہے
3. **منصوبہ بندی**: اسٹیپس تیار کرتا ہے:
   - کچن کی طرف جائیں
   - CLIP کا استعمال کرتے ہوئے "red mug" تلاش کریں
   - ٹیبل کی طرف آئیں
   - مگ کو تھامیں
   - صارف کی طرف جائیں
   - مگ ہاتھ دیں
4. **این ایکشن**:
   - **اسٹیپ 1**: "کچن کی طرف جا رہا ہے..." (TTS فیڈ بیک)
   - **اسٹیپ 2**: کیمرہ ٹیبل کا منظر کیپچر کرتا ہے → CLIP (x, y) پکسل پر لال مگ کی شناخت کرتا ہے → 3D پوائنٹ میں تبدیل کریں
   - **اسٹیپ 3**: "ٹیبل کی طرف آ رہا ہے..." → گریس سے پہلے کی پوزیشن پر جائیں
   - **اسٹیپ 4**: MoveIt گریس ٹریجکٹری کا منصوبہ بندی کرتا ہے → گریپر کو بند کریں
   - **اسٹیپ 5**: "آپ کی طرف واپس آ رہا ہے..." → پیچھے جائیں
   - **اسٹیپ 6**: "یہ آپ کا لال مگ ہے۔" → ہاتھ دینے کے لئے بازو بڑھائیں

**موافق برتاؤ**: اگر ٹیبل پر "red mug" نہ ملے:
- **دوبارہ منصوبہ بندی**: "میں کاؤنٹر پر لال مگ نہیں دیکھ رہا ہوں۔ کیا میں ڈش ریک چیک کروں؟"
- **صارف**: "ہاں، ریک چیک کریں۔"
- **جاری**: منصوبہ اپ ڈیٹ کریں اور نیا مقام تلاش کریں

## تکنیکی ضروریات

### ہارڈ ویئر
- ہیومنوائڈ روبوٹ پلیٹ فارم (یا Gazebo/Isaac Sim میں مماثل)
- RGB-D کیمرہ (Intel RealSense D435، Kinect Azure)
- وائس I/O کے لئے مائیکروفون اور اسپیکر
- 8GB+ VRAM کے ساتھ GPU (NVIDIA RTX 3060 Ti یا بہتر)
- فورس/ٹورک سینسنگ کے ساتھ گریپر

### سافٹ ویئر اسٹیک
- **ROS 2 Humble** Ubuntu 22.04 پر
- **Nav2** خودکار نیوی گیشن کے لئے
- **MoveIt 2** مینوپولیشن منصوبہ بندی کے لئے
- **OpenAI API** رسائی (GPT-4، Whisper، TTS)
- **Python 3.10+** PyTorch، transformers، OpenCV کے ساتھ
- **MediaPipe، CLIP، YOLOv8** ادراک کے لئے

### ترقی کا ماحول
```bash
# کور انحصار انسٹال کریں
sudo apt update
sudo apt install -y ros-humble-nav2-* ros-humble-moveit python3-pip

# Python پیکیجز انسٹال کریں
pip install openai whisper clip torch torchvision opencv-python mediapipe ultralytics pyttsx3

# کیپسٹون ورک سپیس کلون کریں
mkdir -p ~/capstone_ws/src
cd ~/capstone_ws/src
git clone <your_capstone_repo>

# ورک سپیس بنائیں
cd ~/capstone_ws
colcon build --symlink-install
source install/setup.bash
```

## پروجیکٹ کے میل سٹونز

### میل سٹون 1: وائس انٹرفیس (ہفتہ 13 دن 1-2)
- ویک ورڈ کے ذریعہ چالو کردہ سننا لاگو کریں
- ٹرانسکرپشن کے لئے Whisper کا انضمام
- سٹرکچرڈ انٹینٹس میں کمانڈز پارس کریں
- تصدیق کے لئے TTS فیڈ بیک شامل کریں

**فراہم کردہ**: سسٹم جو وائس کمانڈز قبول کرتا ہے اور سمجھ کی تصدیق کرتا ہے

### میل سٹون 2: ویژوئل جڑاؤ (ہفتہ 13 دن 3-4)
- ROS 2 میں کیمرہ فیڈ سیٹ اپ کریں
- اشیاء کی جگہ کے لئے CLIP کا انضمام
- ڈیپتھ بیسڈ 3D کوآرڈینیٹ تبدیلی لاگو کریں
- ریفرنگ ایکسپریشنز کی جانچ کریں ("بائیں طرف والا مگ")

**فراہم کردہ**: سسٹم جو قدرتی زبان کی تفصیلات سے اشیاء کی جگہ لگاتا ہے

### میل سٹون 3: ٹاسک منصوبہ بندی (ہفتہ 13 دن 5)
- GPT-4 ٹاسک ڈیکوم پوزیشن لاگو کریں
- ReAct انجام دہی لوپ تیار کریں
- دنیا کی حالت ٹریکنگ شامل کریں (اشیاء کے مقامات، روبوٹ کی پوز)

**فراہم کردہ**: سسٹم جو متعدد اسٹیپ ٹاسکس کا منصوبہ بندی اور انجام دہی کرتا ہے

### میل سٹون 4: مکمل انضمام (ہفتہ 13 دن 6-7)
- تمام ذیلی سسٹمز کو جوڑیں (وائس → منصوبہ بندی → ویژن → ایکشن)
- خرابی کا انتظام اور بحالی لاگو کریں
- متبادل ان پٹ کے طور پر گیسچر کمانڈز شامل کریں
- جسمانی روبوٹ پر یا زیادہ درست سیمولیشن پر اتاریں

**فراہم کردہ**: اینڈ ٹو اینڈ خودکار ہیومنوائڈ اسسٹنٹ

## جائزہ کے معیار

آپ کا کیپسٹون ان کے مطابق جائزہ لیا جائے گا:

**کارکردگی (40%)**:
- 5/5 ٹیسٹ منظرناموں کو درست طریقے سے انجام دیتے ہیں (لینا، رکھنا، نیوی گیشن، تلاش، مشترکہ ٹاسک)
- کنارے کے کیسز کو سنبھالتا ہے (شے نہ ملنا، راستہ مسدود، گریس ناکامی)
- ابتدائی منصوبہ ناکام ہونے پر موافق دوبارہ منصوبہ بندی

**انضمام (25%)**:
- وائس، ویژن، منصوبہ بندی، اور کنٹرول کے درمیان بے داغ ہم آہنگی
- ریل ٹائم کارکردگی (< 5s لیٹنسی کمانڈ سے ایکشن شروع تک)
- ذیلی سسٹمز میں مضبوط خرابی کا انتظام

**صارف کا تجربہ (20%)**:
- قدرتی زبان کی بات چیت (واضح TTS فیڈ بیک، تصدیقی حلقہ جات)
- محفوظ آپریشن (کالیژن ایوائڈنس، فورس حدیں)
- سمجھدار گیسچر کمانڈز

**کوڈ کی معیار (15%)**:
- واضح انٹرفیسز کے ساتھ ماڈیولر آرکیٹیکچر
- جامع خرابی کا انتظام
- ان لائن دستاویزات اور تبصرے

## ٹیسٹ منظرنامے

ان ٹاسکس پر اپنے سسٹم کا مظاہرہ کریں:

1. **لینا اور پہنچانا**: "میرے لئے الماری سے نیلا پانی کی بوتل لاؤ"
2. **متعدد اشیاء کا ٹاسک**: "تمام مگز کو ڈش ریک پر منتقل کر کے ٹیبل صاف کریں"
3. **تلاش اور رپورٹ**: "کیا ڈیسک پر لیپ ٹاپ ہے؟ اگر ہے تو اس کا رنگ کیا ہے؟"
4. **مشترکہ پکنگ**: "میرے کھانا تیار کرنے میں مدد کریں۔ پہلے کٹنگ بورڈ لائیں، پھر چاقو۔"
5. **گیسچر اوور رائیڈ**: متعدد امیدواروں کے موجود ہونے پر گریسنگ کے لئے کون سی شے کو اشارہ کریں

## اگلے اقدامات

آپ نے کیپسٹون آرکیٹیکچر اور ضروریات کا جائزہ لیا ہے۔ **ہفتہ 13: کیپسٹون امپلیمنٹیشن** میں، آپ مکمل ملٹی موڈل کنٹرول تک جانے کے لئے وائس ٹو ایکشن پائپ لائن سے شروع کرتے ہوئے ایک ایک قدم بڑھاتے ہوئے انضمام شدہ سسٹم تیار کریں گے۔

## وسائل

- **کوڈ ریپوزٹری**: `https://github.com/yourname/vla-capstone`
- **دستاویزات**: سسٹم آرکیٹیکچر ڈائیگرامز، API حوالہ جات
- **سپورٹ**: آفس آورز (کورس صفحہ میں لنک)، بحث کا فورم
- **ڈیمو ویڈیوز**: ہر میل سٹون کے لئے حوالہ امپلیمنٹیشنز

خودکار ہیومنوائڈ بنانے کے لئے تیار ہیں؟ آئیے امپلیمنٹیشن پر بڑھیں۔